{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bca4c64b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (10240, 14)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, make_scorer, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate, cross_val_predict\n",
    "\n",
    "column_names = [\n",
    "    'id',\n",
    "    'label',\n",
    "    'statement',\n",
    "    'subject',\n",
    "    'speaker',\n",
    "    'job_title',\n",
    "    'state_info',\n",
    "    'party_affiliation',\n",
    "    'barely_true_counts',\n",
    "    'false_counts',\n",
    "    'half_true_counts',\n",
    "    'mostly_true_counts',\n",
    "    'pants_on_fire_counts',\n",
    "    'context'\n",
    "]\n",
    "\n",
    "#Load the datasets\n",
    "train_df = pd.read_csv('data/raw/train.tsv', sep='\\t', names=column_names)\n",
    "valid_df = pd.read_csv('data/raw/valid.tsv', sep='\\t', names=column_names)\n",
    "test_df = pd.read_csv('data/raw/test.tsv', sep='\\t', names=column_names)\n",
    "\n",
    "print(f\"Training set shape: {train_df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "27b6fee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Data shapes after converting to binary labels --\n",
      "Training set shape: (8126, 15)\n",
      "Validation set shape: (1036, 15)\n",
      "Test set shape: (1002, 15)\n",
      "\n",
      "-- Label distribution in training set --\n",
      "label_binary\n",
      "0    4488\n",
      "1    3638\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_binary_labels(df):\n",
    "    #define mapping\n",
    "    label_map = {\n",
    "        'true': 1,\n",
    "        'mostly-true': 1,\n",
    "        'false' : 0,\n",
    "        'pants-fire': 0,\n",
    "        'barely-true': 0,\n",
    "    }\n",
    "\n",
    "    #create a copy to avoid SettingWithCopyWarning\n",
    "    df_copy = df.copy()\n",
    "    #apply mapping\n",
    "    df_copy['label_binary'] = df_copy['label'].map(label_map)\n",
    "    # drop rows where label is not in map\n",
    "    df_copy.dropna(subset=['label_binary'], inplace=True)\n",
    "    #convert new label column to int\n",
    "    df_copy['label_binary'] = df_copy['label_binary'].astype(int)\n",
    "    df_copy['statement'].fillna('', inplace=True) #handle potential missing statements\n",
    "    return df_copy\n",
    "\n",
    "# apply the function to each dataframe\n",
    "train_binary_df = create_binary_labels(train_df)\n",
    "valid_binary_df = create_binary_labels(valid_df)\n",
    "test_binary_df = create_binary_labels(test_df)\n",
    "\n",
    "print(\"-- Data shapes after converting to binary labels --\")\n",
    "print(f\"Training set shape: {train_binary_df.shape}\")\n",
    "print(f\"Validation set shape: {valid_binary_df.shape}\")\n",
    "print(f\"Test set shape: {test_binary_df.shape}\")    \n",
    "\n",
    "print(\"\\n-- Label distribution in training set --\")\n",
    "print(train_binary_df['label_binary'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b107d58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 5-fold cross-validation...\n",
      "Cross-validation completed.\n",
      "\n",
      "--- Cross-Validation Results (Mean +/- Std Dev) ---\n",
      "accuracy: 0.625 +/- 0.007\n",
      "precision_false:: 0.638 +/- 0.006\n",
      "recall_false: 0.742 +/- 0.011\n",
      "f1_false: 0.686 +/- 0.006\n",
      "precision_true: 0.602 +/- 0.010\n",
      "recall_true: 0.481 +/- 0.014\n",
      "f1_true: 0.535 +/- 0.010\n",
      "\n",
      "--- Aggregated Classfication Report from Cross-Validation ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.64      0.74      0.69      4488\n",
      "        True       0.60      0.48      0.53      3638\n",
      "\n",
      "    accuracy                           0.63      8126\n",
      "   macro avg       0.62      0.61      0.61      8126\n",
      "weighted avg       0.62      0.63      0.62      8126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # define the feature and target variables\n",
    "# x_train = train_binary_df['statement']\n",
    "# y_train = train_binary_df['label_binary']\n",
    "\n",
    "# x_valid = valid_binary_df['statement']\n",
    "# y_valid = valid_binary_df['label_binary']\n",
    "\n",
    "# #create pipeline\n",
    "# pipeline = Pipeline([\n",
    "#     ('tfidf', TfidfVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "#     ('clf', LogisticRegression(solver='liblinear', random_state=42))\n",
    "# ])\n",
    "\n",
    "# #rain the model\n",
    "# print(\"\\n-- Training the model --\")\n",
    "# pipeline.fit(x_train, y_train)\n",
    "# print(\"Model training completed.\")\n",
    "\n",
    "# #make predictions on validation set\n",
    "# y_pred = pipeline.predict(x_valid)\n",
    "\n",
    "# #print classification report\n",
    "# print(\"\\n-- Classification Report on Validation Set --\")\n",
    "# print(classification_report(y_valid, y_pred, target_names=['False', 'True']))\n",
    "\n",
    "# define the feature and target variables for the full training set\n",
    "x = train_binary_df['statement']\n",
    "y = train_binary_df['label_binary']\n",
    "\n",
    "# create the pipeline(TF-IDF + Logistic Regression)\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "    ('clf', LogisticRegression(solver='liblinear', random_state=42))\n",
    "])\n",
    "\n",
    "# define the cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# define the scoring metrics we want to collect\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision_false:': make_scorer(precision_score, pos_label=0),\n",
    "    'recall_false': make_scorer(recall_score, pos_label=0),\n",
    "    'f1_false': make_scorer(f1_score, pos_label=0),\n",
    "    'precision_true' : make_scorer(precision_score, pos_label=1),\n",
    "    'recall_true': make_scorer(recall_score, pos_label=1),\n",
    "    'f1_true': make_scorer(f1_score, pos_label=1)\n",
    "}\n",
    "\n",
    "# perform cross-validation\n",
    "print(\"Performing 5-fold cross-validation...\")\n",
    "cv_results = cross_validate(pipeline, x, y, cv=cv, scoring=scoring, return_train_score=False)\n",
    "print(\"Cross-validation completed.\")\n",
    "\n",
    "# print the mean and standard deviation of the results\n",
    "print(\"\\n--- Cross-Validation Results (Mean +/- Std Dev) ---\")\n",
    "for metric_name, scores in cv_results.items():\n",
    "    if metric_name.startswith('test_') : # only interested in test scores\n",
    "        print(f\"{metric_name[5:]}: {scores.mean():.3f} +/- {scores.std():.3f}\")\n",
    "\n",
    "# to get per-class precision, recall, f1, we need to do more work\n",
    "# cross_validate w/ 'precision_score' etc. by default calcualtes for the positive class (1)\n",
    "# we need to specify pos_label for each class or calculate manually\n",
    "# for simplicity, let's get the overall classification repot from cross_val_predict\n",
    "\n",
    "print(\"\\n--- Aggregated Classfication Report from Cross-Validation ---\")\n",
    "y_pred_cv = cross_val_predict(pipeline, x, y, cv=cv)\n",
    "print(classification_report(y, y_pred_cv, target_names=['False','True']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d00bfe6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Training and Evaluation Naive Bayes Model ---\n",
      "\n",
      "Performing 5-fold cross-validation for Naive Bayes...\n",
      "Cross-validation for Naive Bayes completed.\n",
      "\n",
      "--- Naive Bayes Cross-Validation Results (Mean +/- Std Dev) ---\n",
      "accuracy: 0.614 +/- 0.008\n",
      "precision_false:: 0.608 +/- 0.005\n",
      "recall_false: 0.845 +/- 0.011\n",
      "f1_false: 0.707 +/- 0.007\n",
      "precision_true: 0.632 +/- 0.019\n",
      "recall_true: 0.328 +/- 0.008\n",
      "f1_true: 0.432 +/- 0.010\n",
      "\n",
      "--- Naive Bayes Aggregated Classfication Report from Cross-Validation ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.61      0.85      0.71      4488\n",
      "        True       0.63      0.33      0.43      3638\n",
      "\n",
      "    accuracy                           0.61      8126\n",
      "   macro avg       0.62      0.59      0.57      8126\n",
      "weighted avg       0.62      0.61      0.58      8126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Improvement 2: Multionomial Naive Bayes Classifier\n",
    "print(\"---- Training and Evaluation Naive Bayes Model ---\")\n",
    "\n",
    "# create the Naieve Bayes pipleine\n",
    "nb_pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english', ngram_range=(1,2))),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "# We can reuse the same data (x,y) and cross-validation strategy (cv) from the previous cells\n",
    "\n",
    "# perform cross-validation for Naive Bayes\n",
    "print(\"\\nPerforming 5-fold cross-validation for Naive Bayes...\")\n",
    "nb_cv_results = cross_validate(nb_pipeline, x, y, cv=cv, scoring=scoring, return_train_score=False)\n",
    "print(\"Cross-validation for Naive Bayes completed.\")    \n",
    "\n",
    "# print the mean and standard deviation of the results for Naive Bayes\n",
    "print(\"\\n--- Naive Bayes Cross-Validation Results (Mean +/- Std Dev) ---\")\n",
    "for metric_name, scores in nb_cv_results.items():\n",
    "    if metric_name.startswith('test_'): #only interested in test scores\n",
    "        print(f\"{metric_name[5:]}: {scores.mean():.3f} +/- {scores.std():.3f}\")\n",
    "\n",
    "# get aggregated classification report for Naive Bayes\n",
    "print(\"\\n--- Naive Bayes Aggregated Classfication Report from Cross-Validation ---\")\n",
    "y_pred_nb_cv = cross_val_predict(nb_pipeline, x, y, cv=cv)\n",
    "print(classification_report(y, y_pred_nb_cv, target_names=['False','True']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cec6eb55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analyzing Most Signficant Features for Logistic Regression ---\n",
      "\n",
      "Retraining the pipeline on the full training data...\n",
      "Retraining completed.\n",
      "\n",
      "--- Top 15 Features Indicative of 'False' Class ---\n",
      "            feature  coefficient\n",
      "39676     obamacare    -2.383089\n",
      "39371         obama    -2.068235\n",
      "51558          says    -1.674549\n",
      "43706          plan    -1.568515\n",
      "64783     wisconsin    -1.507090\n",
      "48750           rep    -1.487791\n",
      "36334      medicare    -1.409577\n",
      "63504        walker    -1.368859\n",
      "39794        obamas    -1.358984\n",
      "52698  scott walker    -1.273747\n",
      "56597      stimulus    -1.198985\n",
      "46957         raise    -1.147613\n",
      "12324       clinton    -1.138387\n",
      "10367          care    -1.136506\n",
      "64538         white    -1.112952\n",
      "\n",
      "--- Top 15 Features Indicative of 'True' Class ---\n",
      "         feature  coefficient\n",
      "2371          60     1.299957\n",
      "36518    members     1.337882\n",
      "4999    american     1.392508\n",
      "16609       debt     1.457837\n",
      "37742     months     1.504054\n",
      "14773    country     1.521157\n",
      "27535    highest     1.545490\n",
      "14731  countries     1.548371\n",
      "60016      times     1.646325\n",
      "36957    million     1.654478\n",
      "6529     average     1.697885\n",
      "26602       half     1.826374\n",
      "24708    georgia     1.840916\n",
      "16272        day     1.928826\n",
      "42725    percent     2.977464\n"
     ]
    }
   ],
   "source": [
    "# --- improvement 3: Feature Analysis for Logistic Regression ---\n",
    "print(\"--- Analyzing Most Signficant Features for Logistic Regression ---\")\n",
    "\n",
    "# first, we need to retrain the pipeline on the full training data to get a single model to inspect.\n",
    "# (x and y are already defined from the previous cells)\n",
    "print(\"\\nRetraining the pipeline on the full training data...\")\n",
    "pipeline.fit(x,y)\n",
    "print(\"Retraining completed.\")\n",
    "\n",
    "# extract the trained vectorizer and classifier from the pipeline\n",
    "vectorizer = pipeline.named_steps['tfidf']\n",
    "classifier = pipeline.named_steps['clf']\n",
    "\n",
    "# get the feature names (the words and bigrams)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# get the coefficients from the logistic regression model\n",
    "# the classifier has one coefficient per feature \n",
    "coefficients = classifier.coef_[0]\n",
    "\n",
    "# create a dataframe to view the features and their coefficients\n",
    "coef_df = pd.DataFrame({'feature': feature_names, 'coefficient': coefficients})\n",
    "\n",
    "# sort the DataFrame to find the top features\n",
    "# most negative coefficients indicate strong association with class 0 (False)\n",
    "# most positive coefficients indicate strong association with class 1 (True)\n",
    "sorted_coef_df = coef_df.sort_values(by='coefficient', ascending=True)\n",
    "\n",
    "# Print the top 15 features for each class\n",
    "print(\"\\n--- Top 15 Features Indicative of 'False' Class ---\")\n",
    "print(sorted_coef_df.head(15))\n",
    "\n",
    "print(\"\\n--- Top 15 Features Indicative of 'True' Class ---\")\n",
    "print(sorted_coef_df.tail(15))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
