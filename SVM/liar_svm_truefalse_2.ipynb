{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from textblob import TextBlob\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# load and setup\n",
        "column_names = [\n",
        "    'id', 'label', 'statement', 'subject', 'speaker', 'job_title',\n",
        "    'state_info', 'party_affiliation', 'barely_true_counts',\n",
        "    'false_counts', 'half_true_counts', 'mostly_true_counts',\n",
        "    'pants_on_fire_counts', 'context'\n",
        "]\n",
        "\n",
        "train_df = pd.read_csv('train.tsv', sep='\\t', header=None, names=column_names)\n",
        "test_df = pd.read_csv('test.tsv', sep='\\t', header=None, names=column_names)\n",
        "valid_df = pd.read_csv('valid.tsv', sep='\\t', header=None, names=column_names)\n",
        "\n",
        "# combine train and valid sets\n",
        "full_train_df = pd.concat([train_df, valid_df], ignore_index=True)\n",
        "\n",
        "# feature engineering\n",
        "\n",
        "# use ratios of history instead of raw counts\n",
        "def create_ratios(df):\n",
        "    history_cols = ['barely_true_counts', 'false_counts', 'half_true_counts',\n",
        "                    'mostly_true_counts', 'pants_on_fire_counts']\n",
        "\n",
        "    # Ensure numeric\n",
        "    for col in history_cols:\n",
        "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
        "\n",
        "    # Total statements\n",
        "    df['total_history'] = df[history_cols].sum(axis=1)\n",
        "    df['total_history'] = df['total_history'].replace(0, 1) # Avoid div/0\n",
        "\n",
        "    # Calculate Ratios\n",
        "    df['lie_ratio'] = (df['false_counts'] + df['pants_on_fire_counts']) / df['total_history']\n",
        "    df['truth_ratio'] = (df['mostly_true_counts'] + df['half_true_counts']) / df['total_history']\n",
        "    return df\n",
        "\n",
        "full_train_df = create_ratios(full_train_df)\n",
        "test_df = create_ratios(test_df)\n",
        "\n",
        "# B. use TextBlob to anaylyze sentiment of articles\n",
        "def get_sentiment(text):\n",
        "    return TextBlob(str(text)).sentiment.polarity\n",
        "\n",
        "def get_subjectivity(text):\n",
        "    return TextBlob(str(text)).sentiment.subjectivity\n",
        "\n",
        "full_train_df['sentiment'] = full_train_df['statement'].apply(get_sentiment)\n",
        "full_train_df['subjectivity'] = full_train_df['statement'].apply(get_subjectivity)\n",
        "\n",
        "test_df['sentiment'] = test_df['statement'].apply(get_sentiment)\n",
        "test_df['subjectivity'] = test_df['statement'].apply(get_subjectivity)\n",
        "\n",
        "# general preprocessing\n",
        "def combine_text_cols(df):\n",
        "    return (df['statement'].fillna('') + ' ' +\n",
        "            df['context'].fillna('') + ' ' +\n",
        "            df['job_title'].fillna(''))\n",
        "\n",
        "full_train_df['full_text'] = combine_text_cols(full_train_df)\n",
        "test_df['full_text'] = combine_text_cols(test_df)\n",
        "\n",
        "# make all categories equal in side\n",
        "def group_rare(df, col, top_items):\n",
        "    return df[col].apply(lambda x: x if x in top_items else 'other')\n",
        "\n",
        "for col in ['party_affiliation', 'subject']:\n",
        "    # identify top 10 in the combined training set\n",
        "    top_items = full_train_df[col].value_counts().nlargest(10).index\n",
        "\n",
        "    # Apply to both\n",
        "    full_train_df[col] = group_rare(full_train_df, col, top_items)\n",
        "    test_df[col] = group_rare(test_df, col, top_items)\n",
        "\n",
        "# map 6 targets to 2\n",
        "def map_to_binary(label):\n",
        "    if label in ['true', 'mostly-true', 'half-true']:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "# Create X and y\n",
        "y_train = full_train_df['label'].apply(map_to_binary)\n",
        "y_test = test_df['label'].apply(map_to_binary)\n",
        "\n",
        "X_train = full_train_df.drop('label', axis=1)\n",
        "X_test = test_df.drop('label', axis=1)\n",
        "\n",
        "# full pipeline construction\n",
        "text_feature = 'full_text'\n",
        "categorical_features = ['party_affiliation', 'subject']\n",
        "numerical_features = [\n",
        "    'barely_true_counts', 'false_counts', 'half_true_counts',\n",
        "    'mostly_true_counts', 'pants_on_fire_counts',\n",
        "    'total_history', 'lie_ratio', 'truth_ratio',\n",
        "    'sentiment', 'subjectivity'\n",
        "]\n",
        "\n",
        "text_transformer = Pipeline(steps=[\n",
        "    ('tfidf', TfidfVectorizer(\n",
        "        min_df=3,\n",
        "        max_df=0.9,\n",
        "        ngram_range=(1, 2),\n",
        "        stop_words='english',\n",
        "        sublinear_tf=True\n",
        "    ))\n",
        "])\n",
        "\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('text', text_transformer, text_feature),\n",
        "        ('cat', cat_transformer, categorical_features),\n",
        "        ('num', num_transformer, numerical_features)\n",
        "    ])\n",
        "\n",
        "# hybrid SVM and XGBoost model\n",
        "clf_linear = LogisticRegression(C=1.0, solver='liblinear', max_iter=5000)\n",
        "\n",
        "clf_xgb = XGBClassifier(\n",
        "    n_estimators=200,\n",
        "    learning_rate=0.05,\n",
        "    max_depth=6,\n",
        "    use_label_encoder=False,\n",
        "    eval_metric='logloss',\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "ensemble_model = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('voting', VotingClassifier(\n",
        "        estimators=[\n",
        "            ('lr', clf_linear),\n",
        "            ('xgb', clf_xgb)\n",
        "        ],\n",
        "        voting='soft'\n",
        "    ))\n",
        "])\n",
        "\n",
        "# train/predict\n",
        "print(\"Training Ensemble Model on Full Data (Train + Valid)...\")\n",
        "ensemble_model.fit(X_train, y_train)\n",
        "\n",
        "print(\"Predicting on Test Set...\")\n",
        "predictions = ensemble_model.predict(X_test)\n",
        "\n",
        "# results\n",
        "print(\"\\nResults\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, predictions):.2%}\")\n",
        "print(\"\\nClassification Report\")\n",
        "print(classification_report(y_test, predictions, target_names=['Fake', 'Real']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJ3RbYCnff8D",
        "outputId": "6a9cd2d1-a2dd-4509-8357-96c4941015b2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading datasets...\n",
            "Combining Train and Validation sets...\n",
            "Engineering features...\n",
            "Training Ensemble Model on Full Data (Train + Valid)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [23:20:00] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicting on Test Set...\n",
            "\n",
            "Results\n",
            "Accuracy: 74.82%\n",
            "\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "        Fake       0.74      0.65      0.69       553\n",
            "        Real       0.75      0.82      0.79       714\n",
            "\n",
            "    accuracy                           0.75      1267\n",
            "   macro avg       0.75      0.74      0.74      1267\n",
            "weighted avg       0.75      0.75      0.75      1267\n",
            "\n"
          ]
        }
      ]
    }
  ]
}