{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Raw Data"
      ],
      "metadata": {
        "id": "gAx4mpRgSkp9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "EJrKJ4-LN-5j"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "# imports for base SVM\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "#imports for cleaning data\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# imports for advanced SVM (transforming features from categorical to numerical)\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from sklearn.decomposition import TruncatedSVD"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# rename columns for ease\n",
        "column_names = [\n",
        "    'id',                # Column 1\n",
        "    'label',             # Column 2\n",
        "    'statement',         # Column 3\n",
        "    'subject',           # Column 4\n",
        "    'speaker',           # Column 5\n",
        "    'job_title',         # Column 6\n",
        "    'state_info',        # Column 7\n",
        "    'party_affiliation', # Column 8\n",
        "    'barely_true_counts',# Column 9\n",
        "    'false_counts',      # Column 10\n",
        "    'half_true_counts',  # Column 11\n",
        "    'mostly_true_counts',# Column 12\n",
        "    'pants_on_fire_counts',# Column 13\n",
        "    'context'            # Column 14\n",
        "]\n",
        "\n",
        "# load datasets\n",
        "train_df = pd.read_csv('train.tsv', sep='\\t', header=None, names=column_names)\n",
        "valid_df = pd.read_csv('valid.tsv', sep='\\t', header=None, names=column_names)\n",
        "test_df = pd.read_csv('test.tsv', sep='\\t', header=None, names=column_names)\n",
        "\n",
        "# extract x and y for each set, keep only our statement and label (target)\n",
        "# will add more columns later\n",
        "X_train = train_df['statement']\n",
        "y_train = train_df['label']\n",
        "\n",
        "X_valid = valid_df['statement']\n",
        "y_valid = valid_df['label']\n",
        "\n",
        "X_test = test_df['statement']\n",
        "y_test = test_df['label']\n",
        "\n",
        "print(\"Data Loaded Successfully!\")\n",
        "print(f\"Training Set: {X_train.shape[0]} samples\")\n",
        "print(f\"Validation Set: {X_valid.shape[0]} samples\")\n",
        "print(f\"Test Set: {X_test.shape[0]} samples\")\n",
        "\n",
        "print(\"\\nFirst Sample:\")\n",
        "print(f\"Label: {y_train.iloc[0]}\")\n",
        "print(f\"Statement: {X_train.iloc[0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rOgeJRFONlK",
        "outputId": "081bd0e6-7cbe-47b4-c043-aa18e24c2ea8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data Loaded Successfully!\n",
            "Training Set: 10240 samples\n",
            "Validation Set: 1284 samples\n",
            "Test Set: 1267 samples\n",
            "\n",
            "First Sample:\n",
            "Label: false\n",
            "Statement: Says the Annies List political group supports third-trimester abortions on demand.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use TF-IDF to reduce common words like \"of\" and \"the\"\n",
        "tfidf = TfidfVectorizer()\n",
        "\n",
        "# fit and transform data using sklearn\n",
        "X_train_vectors = tfidf.fit_transform(X_train)\n",
        "X_test_vectors = tfidf.transform(X_test)\n",
        "\n",
        "# keeps random state the same, remove this if want \"more\" random\n",
        "clf = LinearSVC(random_state=31)\n",
        "\n",
        "# train and test model\n",
        "clf.fit(X_train_vectors, y_train)\n",
        "predictions = clf.predict(X_test_vectors)\n",
        "\n",
        "# print results\n",
        "print(\"\\nResults\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, predictions):.2%}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, predictions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9nYdm0GPPYs",
        "outputId": "d7c39a7a-5054-454f-c911-773855dd58a9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results\n",
            "Accuracy: 24.23%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " barely-true       0.24      0.23      0.23       212\n",
            "       false       0.29      0.31      0.30       249\n",
            "   half-true       0.23      0.23      0.23       265\n",
            " mostly-true       0.20      0.21      0.21       241\n",
            "  pants-fire       0.21      0.16      0.18        92\n",
            "        true       0.25      0.27      0.26       208\n",
            "\n",
            "    accuracy                           0.24      1267\n",
            "   macro avg       0.24      0.23      0.24      1267\n",
            "weighted avg       0.24      0.24      0.24      1267\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Overall Accuray - 24.23%\n",
        "\n",
        "Out of every 100 example news articles, the model predicted the correct label for about 24. Random guessing would be about 16%, so the baseline SVM model is doing decent.\n",
        "\n",
        "The biggest challenge with having 6 results if the difference between labels like \"half-true\" and \"mostly-true\", which could just be the difference of opinions between people. Not surprsing a text-only model struggles with this.\n",
        "\n"
      ],
      "metadata": {
        "id": "Tkwny2mYQxOg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cleaned Data"
      ],
      "metadata": {
        "id": "J5MPJ13_Shae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6eyFB7roQxBf",
        "outputId": "e84dda06-2a67-4596-f55f-2c3723c1c260"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    # convert all text to lowercase\n",
        "    text = str(text).lower()\n",
        "\n",
        "    # replace numbers with 'num'\n",
        "    text = re.sub(r'\\d+', 'num', text)\n",
        "\n",
        "    # Remove punctuation\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    # Tokenize\n",
        "    words = text.split()\n",
        "\n",
        "    # Remove Stopwords & Lemmatize\n",
        "\n",
        "    cleaned_words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "\n",
        "    return ' '.join(cleaned_words)"
      ],
      "metadata": {
        "id": "3_HmeiX_TPmR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_clean = X_train.apply(clean_text)\n",
        "X_test_clean = X_test.apply(clean_text)\n",
        "\n",
        "# run pipeline\n",
        "tfidf_clean = TfidfVectorizer(min_df=3)\n",
        "\n",
        "# vectorizing data\n",
        "X_train_vectors_clean = tfidf_clean.fit_transform(X_train_clean)\n",
        "X_test_vectors_clean = tfidf_clean.transform(X_test_clean)\n",
        "\n",
        "# training\n",
        "clf_clean = LinearSVC(random_state=42, max_iter=10000) # Increased max_iter for convergence\n",
        "clf_clean.fit(X_train_vectors_clean, y_train)\n",
        "\n",
        "# predicting\n",
        "predictions_clean = clf_clean.predict(X_test_vectors_clean)"
      ],
      "metadata": {
        "id": "AwiM8wiYTque"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nCleaned results\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, predictions_clean):.2%}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, predictions_clean))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzQThZJBTszd",
        "outputId": "90141fc2-43e8-4b88-c23e-19228d33fb94"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cleaned results\n",
            "Accuracy: 21.07%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " barely-true       0.18      0.18      0.18       212\n",
            "       false       0.22      0.22      0.22       249\n",
            "   half-true       0.24      0.23      0.23       265\n",
            " mostly-true       0.19      0.20      0.20       241\n",
            "  pants-fire       0.19      0.16      0.18        92\n",
            "        true       0.22      0.23      0.22       208\n",
            "\n",
            "    accuracy                           0.21      1267\n",
            "   macro avg       0.21      0.21      0.21      1267\n",
            "weighted avg       0.21      0.21      0.21      1267\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advanced SVM (more categories)"
      ],
      "metadata": {
        "id": "zw4PMrHBXfVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define features we want to use\n",
        "text_feature = 'statement'\n",
        "categorical_features = ['subject', 'speaker', 'job_title', 'state_info', 'party_affiliation']\n",
        "numerical_features = ['barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts']\n",
        "\n",
        "# use TF-IDF\n",
        "text_transformer = Pipeline(steps=[\n",
        "    ('tfidf', TfidfVectorizer(\n",
        "        min_df=3,\n",
        "        stop_words='english',\n",
        "        ngram_range=(1, 2),    # <-- add bigrams\n",
        "        sublinear_tf=True,     # optional but often helps\n",
        "        max_df=0.9             # drop super-common tokens\n",
        "    )),\n",
        "    ('svd', TruncatedSVD(n_components=500, random_state=31))\n",
        "])\n",
        "\n",
        "# convert categorical data using one hot encoding\n",
        "cat_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# numerical transform, standardized\n",
        "num_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# create full pipeline (preprocessing -> training)\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('text', text_transformer, text_feature),\n",
        "        ('cat', cat_transformer, categorical_features),\n",
        "        ('num', num_transformer, numerical_features)\n",
        "    ])\n",
        "\n",
        "model_advanced = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LinearSVC(C=0.1,random_state=31, max_iter=100000))\n",
        "])\n",
        "\n",
        "# train and predict\n",
        "X_train_full = train_df.drop('label', axis=1)\n",
        "X_test_full = test_df.drop('label', axis=1)\n",
        "\n",
        "# cast both as float\n",
        "X_train_full[numerical_features] = X_train_full[numerical_features].astype(float)\n",
        "X_test_full[numerical_features] = X_test_full[numerical_features].astype(float)\n",
        "\n",
        "model_advanced.fit(X_train_full, y_train)\n",
        "predictions_adv = model_advanced.predict(X_test_full)"
      ],
      "metadata": {
        "id": "XQJRcJexXtHd"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- ADVANCED PIPELINE RESULTS (Text + Metadata) ---\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, predictions_adv):.2%}\")\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, predictions_adv))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWsvde1QYeDI",
        "outputId": "71e249ad-c628-4692-8841-d7dab05f8dfb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- ADVANCED PIPELINE RESULTS (Text + Metadata) ---\n",
            "Accuracy: 28.73%\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            " barely-true       0.27      0.20      0.23       212\n",
            "       false       0.28      0.29      0.28       249\n",
            "   half-true       0.27      0.29      0.28       265\n",
            " mostly-true       0.30      0.36      0.33       241\n",
            "  pants-fire       0.38      0.26      0.31        92\n",
            "        true       0.29      0.29      0.29       208\n",
            "\n",
            "    accuracy                           0.29      1267\n",
            "   macro avg       0.30      0.28      0.29      1267\n",
            "weighted avg       0.29      0.29      0.29      1267\n",
            "\n"
          ]
        }
      ]
    }
  ]
}